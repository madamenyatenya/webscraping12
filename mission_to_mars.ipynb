{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                                                           # numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd                                                          # pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from splinter import Browser                                                 # browser module from splinter library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver                                               # webdriver module from selenium library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs                                          # BeautifulSoup module from bs4 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as req                                                       # requests library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NASA Mars News - Scrape the NASA Mars News Site and collect the latest News Title and Paragragh Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_data = {}                                                               # initializes empty dictionary\n",
    "paragraph_text = []                                                          # initializes empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://mars.nasa.gov/\"                                          # base URL for finding paragraph text\n",
    "nasa_url = \"https://mars.nasa.gov/news/\"                                     # URL for initial scrape\n",
    "response_1 = req.get(nasa_url)                                               # acquires first response from URL\n",
    "\n",
    "nasa_soup = bs(response_1.text, 'html.parser')                               # sends response to beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_div = nasa_soup.find(class_=\"slide\")                                    # finds class\n",
    "soup_news = soup_div.find_all('a')                                           # finds all anchors\n",
    "news_title = soup_news[1].get_text().strip()                                 # extracts and cleans title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_p = soup_div.find_all('a', href=True)                                   # finds paragraphs\n",
    "soup_p_url = soup_p[0]['href']                                               # gets paragraphs URL\n",
    "paragraph_url = base_url + soup_p_url                                        # concatenates URL for paragraph\n",
    "response_2 = req.get(paragraph_url)                                          # acquires second response from URL\n",
    "para_soup = bs(response_2.text, \"html.parser\")                               # sends response to beautiful soup\n",
    "ww_paragraphs = para_soup.find(class_='wysiwyg_content')                     # finds class\n",
    "paragraphs = ww_paragraphs.find_all('p')                                     # finds paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for paragraph in paragraphs:                                                 # iterates through paragraphs\n",
    "    clean_paragraph = paragraph.get_text().strip()                           # extracts and cleans paragraphs    \n",
    "    paragraph_text.append(clean_paragraph)                                   # appends to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_data[\"news_title\"] = news_title                                         # adds title to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_data[\"paragraph_text_1\"] = paragraph_text[0]                            # adds paragraph summary to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news_data[\"paragraph_text_2\"] = paragraph_text[1]                            # adds paragraph detail to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_title': 'A Piece of Mars is Going Home',\n",
       " 'paragraph_text_1': 'A chunk of Mars will soon be returning home.',\n",
       " 'paragraph_text_2': \"A piece of a meteorite called Sayh al Uhaymir 008 (SaU008) will be carried on board NASA's Mars 2020 rover mission, now being built at the agency's Jet Propulsion Laboratory in Pasadena, California. This chunk will serve as target practice for a high-precision laser on the rover's arm.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data                                                                    # displays dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JPL Mars Space Images - Visit the url for JPL's Featured Space Image. Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Developer note: One of the Gotchas! I ran into with this assignment is that the URL provided does NOT consistently provide images of Mars. In response to this, I resorted to a brute-force attack, in light of assignment time constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = Browser('chrome', headless=False)                                  # defines splinter browser\n",
    "jpl_fullsize_url = 'https://photojournal.jpl.nasa.gov/jpeg/'                 # defines base URL for fullsize images\n",
    "jpl_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"      # defines search URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser.visit(jpl_url)                                                       # visits search URL with automated browser\n",
    "jpl_html = browser.html                                                      # acquires response from URL\n",
    "jpl_soup = bs(jpl_html, 'html.parser')                                       # sends response to beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featured_image_list = []                                                     # initializes empty list\n",
    "\n",
    "for image in jpl_soup.find_all('div',class_=\"img\"):                          # extracts all images\n",
    "    featured_image_list.append(image.find('img').get('src'))                 # appends URL to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_image = featured_image_list[0]                                       # extracts first image found\n",
    "temp_list_1 = feature_image.split('-')                                       # splits on '-' (removes size limiters)\n",
    "temp_list_2 = temp_list_1[0].split('/')                                      # splits on '/' (parses out base filename)\n",
    "featured_image_url = jpl_fullsize_url + temp_list_2[-1] + '.jpg'             # concatenates fullsize image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://photojournal.jpl.nasa.gov/jpeg/PIA22273.jpg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_image_url                                                           # displays URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser.quit()                                                               # closes automated browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mars Weather - Visit the Mars Weather twitter account and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = Browser('chrome', headless=False)                                  # defines browser\n",
    "tweet_url = 'https://twitter.com/marswxreport?lang=en'                       # defines search URL\n",
    "browser.visit(tweet_url)                                                     # visits search URL with automated browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_html = browser.html                                                    # acquires response from URL\n",
    "tweet_soup = bs(tweet_html, 'html.parser')                                   # sends response to beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_info_list = []                                                       # initializes empty list\n",
    "\n",
    "# extracts all tweets from soup\n",
    "for weather_info in tweet_soup.find_all('p',class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\"):\n",
    "    weather_info_list.append(weather_info.text.strip())                      # appends cleaned tweet to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for value in reversed(weather_info_list):                                    # loops through list backwards\n",
    "    if value[:3]=='Sol':                                                     # isolates weather tweet\n",
    "        mars_weather = value                                                 # assigns to variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sol 1962 (Feb 12, 2018), Sunny, high -14C/6F, low -78C/-108F, pressure at 7.38 hPa, daylight 05:40-17:27'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_weather                                                                 # displays tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser.quit()                                                               # closes automated browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mars Facts - Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facts_url = 'https://space-facts.com/mars/'                                  # defines search URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fact_list = pd.read_html(facts_url)                                          # extracts data from URL using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facts_df = fact_list[0]                                                      # converts list to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>Equatorial Diameter:</td>\n",
      "      <td>6,792 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Polar Diameter:</td>\n",
      "      <td>6,752 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Mass:</td>\n",
      "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Moons:</td>\n",
      "      <td>2 (Phobos &amp; Deimos)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Orbit Distance:</td>\n",
      "      <td>227,943,824 km (1.52 AU)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Orbit Period:</td>\n",
      "      <td>687 days (1.9 years)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Surface Temperature:</td>\n",
      "      <td>-153 to 20 Â°C</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>First Record:</td>\n",
      "      <td>2nd millennium BC</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Recorded By:</td>\n",
      "      <td>Egyptian astronomers</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "facts_table = facts_df.to_html(header=False, index=False)                    # converts dataframe to html table\n",
    "print(facts_table)                                                           # displays html table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mars Hemisperes - Visit the USGS Astrogeology site to obtain high resolution images for each of Mars' hemispheres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = Browser('chrome', headless=False)                                  # defines browser                                 \n",
    "\n",
    "# defines search URL\n",
    "usgs_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(usgs_url)                                                      # visits search URL with automated browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usgs_html = browser.html                                                     # acquires response from URL\n",
    "usgs_soup = bs(usgs_html, 'html.parser')                                     # sends response to beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hemisphere_image_urls = []                                                   # Creates empty list\n",
    "\n",
    "products = usgs_soup.find('div', class_='result-list')                       # finds products\n",
    "hemispheres = products.find_all('div', class_='item')                        # finds hemispheres\n",
    "\n",
    "for hemisphere in hemispheres:                                               # iterates through hemispheres\n",
    "    title = hemisphere.find('div', class_='description')\n",
    "    \n",
    "    title_text = title.a.text                                                # extracts cleaned title\n",
    "    title_text = title_text.replace(' Enhanced', '')\n",
    "    browser.click_link_by_partial_text(title_text)                           # (automated) click\n",
    "    \n",
    "    usgs_html = browser.html                                                 # acquires response from URL\n",
    "    usgs_soup = bs(usgs_html, 'html.parser')                                 # sends response to beautiful soup\n",
    "    \n",
    "    image = usgs_soup.find('div', class_='downloads').find('ul').find('li')  # extracts image url\n",
    "    img_url = image.a['href']\n",
    "    \n",
    "    hemisphere_image_urls.append({'title': title_text, 'img_url': img_url})  # adds dictionary to list  \n",
    "    \n",
    "    browser.click_link_by_partial_text('Back')                               # (automated) click back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg',\n",
       "  'title': 'Cerberus Hemisphere'},\n",
       " {'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg',\n",
       "  'title': 'Schiaparelli Hemisphere'},\n",
       " {'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg',\n",
       "  'title': 'Syrtis Major Hemisphere'},\n",
       " {'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg',\n",
       "  'title': 'Valles Marineris Hemisphere'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_image_urls                                                        # displays list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser.quit()                                                               # closes automated browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PythonData)",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}